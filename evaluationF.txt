import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
import os
import matplotlib.pyplot as plt
# from sklearn.metrics import precision_score, recall_score, f1_score

# Define the dataset class (Handles your specific directory structure)
class ForgeryDataset(Dataset):
    def __init__(self, root_dir, split="train", transform_image=None, transform_mask=None):
        print(f"[INFO] Initializing ForgeryDataset for {split} split")
        self.root_dir = root_dir
        self.split = split
        self.transform_image = transform_image
        self.transform_mask = transform_mask

        self.image_paths = []
        self.mask_paths = []

        for category in ["forgery", "no_forgery"]:
            image_dir = os.path.join(root_dir, split, category)
            print(f"[INFO] Scanning directory: {image_dir}")
            for filename in os.listdir(image_dir):
                if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')):
                    self.image_paths.append(os.path.join(image_dir, filename))
                    if category == "forgery":  # Only forgery images have masks
                        mask_filename = os.path.splitext(filename)[0] + "_gt.png"  # Construct mask filename
                        mask_path = os.path.join(root_dir, "mask", "forgery", mask_filename)

                        if os.path.exists(mask_path):
                            self.mask_paths.append(mask_path)
                        else:
                            print(f"[INFO] Warning: Mask not found for {filename}")
                            self.mask_paths.append(None)  # Append None if mask doesn't exist to maintain index alignment
                    else:
                        self.mask_paths.append(None)  # Append None for no_forgery images

        # Filter out images without masks
        self.image_paths, self.mask_paths = zip(*[(img, mask) for img, mask in zip(self.image_paths, self.mask_paths) if mask is not None])
        print(f"[INFO] Dataset initialized with {len(self.image_paths)} images")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        mask_path = self.mask_paths[idx]

        print(f"[INFO] Loading image: {img_path}")
        print(f"[INFO] Loading mask: {mask_path}")

        image = Image.open(img_path).convert("RGB")
        mask = Image.open(mask_path).convert("L")

        if self.transform_image:
            image = self.transform_image(image)

        if self.transform_mask:
            mask = self.transform_mask(mask)
            mask = (mask > 0.5).float()  # Threshold mask to binary (0 or 1)

        return image, mask

# Define the CNN model (U-Net style for segmentation)
class UNet(nn.Module):
    def __init__(self):
        print("[INFO] Initializing U-Net model")
        super(UNet, self).__init__()
        # Define the encoder (downsampling path)
        self.down1 = self.double_conv(3, 64)
        self.down2 = self.double_conv(64, 128)
        self.down3 = self.double_conv(128, 256)
        self.down4 = self.double_conv(256, 512)

        # Define the decoder (upsampling path)
        self.up1 = self.up_conv(512 + 256, 256)  # Adjust input channels for concatenation
        self.up2 = self.up_conv(256 + 128, 128)  # Adjust input channels for concatenation
        self.up3 = self.up_conv(128 + 64, 64)    # Adjust input channels for concatenation
        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)  # Final output layer

        # Other components
        self.pool = nn.MaxPool2d(2, 2)
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

    def double_conv(self, in_c, out_c):
        return nn.Sequential(
            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )

    def up_conv(self, in_c, out_c):
        return nn.Sequential(
            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        print("[INFO] Forward pass through U-Net")
        # Downsample
        d1 = self.down1(x)
        print("[INFO] Completed down1")
        p1 = self.pool(d1)
        d2 = self.down2(p1)
        print("[INFO] Completed down2")
        p2 = self.pool(d2)
        d3 = self.down3(p2)
        print("[INFO] Completed down3")
        p3 = self.pool(d3)
        d4 = self.down4(p3)
        print("[INFO] Completed down4")

        # Upsample
        u1 = self.upsample(d4)
        u1 = torch.cat([u1, d3], dim=1)  # Concatenate with corresponding encoder feature map
        print("[INFO] Concatenated u1 with d3")
        u1 = self.up1(u1)

        u2 = self.upsample(u1)
        u2 = torch.cat([u2, d2], dim=1)
        print("[INFO] Concatenated u2 with d2")
        u2 = self.up2(u2)

        u3 = self.upsample(u2)
        u3 = torch.cat([u3, d1], dim=1)
        print("[INFO] Concatenated u3 with d1")
        u3 = self.up3(u3)

        out = self.out_conv(u3)
        print("[INFO] Completed final output layer")
        return torch.sigmoid(out)  # Sigmoid activation for binary segmentation

def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, device):
    print("[INFO] Starting training loop")
    for epoch in range(num_epochs):
        print(f"[INFO] Epoch {epoch+1}/{num_epochs}")
        epoch_loss = 0.0
        correct_pixels = 0
        total_pixels = 0

        # Training loop
        model.train()  # Set model to training mode
        for i, (images, masks) in enumerate(train_loader):
            print(f"[INFO] Processing batch {i+1}/{len(train_loader)}")
            images = images.to(device)
            masks = masks.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

            # Calculate accuracy (per-pixel)
            predicted_masks = (outputs > 0.5).float()  # Threshold predictions
            correct_pixels += (predicted_masks == masks).sum().item()
            total_pixels += masks.numel()

        epoch_loss /= len(train_loader)
        accuracy = correct_pixels / total_pixels

        print(f"[INFO] Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}")

        # Validation after every epoch
        val_loss, val_accuracy = validate_model(model, test_loader, criterion, device)
        print(f"[INFO] Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}")

    print("[INFO] Training loop complete")
    return epoch_loss, accuracy

def validate_model(model, test_loader, criterion, device):
    print("[INFO] Starting validation loop")
    model.eval()  # Set model to evaluation mode
    val_loss = 0.0
    all_preds = []
    all_labels = []

    with torch.no_grad():  # No gradient computation during validation
        for i, (images, masks) in enumerate(test_loader):
            images = images.to(device)
            masks = masks.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, masks)
            val_loss += loss.item()

            # Threshold the predictions to binary values (0 or 1)
            predicted_masks = (outputs > 0.5).float()  # Convert predictions to binary

            # Collect all predicted and ground truth masks for metrics calculation
            all_preds.append(predicted_masks.view(-1).cpu().numpy())
            all_labels.append(masks.view(-1).cpu().numpy())

    # Flatten the lists of predictions and ground truth
    all_preds = np.concatenate(all_preds)
    all_labels = np.concatenate(all_labels)

    # Ensure predictions and labels are integers (required by sklearn metrics)
    all_preds = all_preds.astype(int)
    all_labels = all_labels.astype(int)

    # Calculate metrics
    accuracy = np.mean(all_preds == all_labels)
   # precision = precision_score(all_labels, all_preds, zero_division=1)  # Avoid division by zero
   # recall = recall_score(all_labels, all_preds, zero_division=1)  # Avoid division by zero
   # f1 = f1_score(all_labels, all_preds, zero_division=1)  # Avoid division by zero

    # Calculate the average loss
    val_loss /= len(test_loader)

    #print(f"[INFO] Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}")
    #return val_loss, accuracy, precision, recall, f1
    print(f"[INFO] Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}")
    return val_loss, accuracy

if __name__ == "__main__":
    print("[INFO] Starting main script")
    root_dir = "dataset2"  # The main directory containing train, test, and mask

    batch_size = 4
    num_epochs = 1
    learning_rate = 0.001
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print(f"[INFO] Using device: {device}")

    transform_image = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
    ])

    transform_mask = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
    ])

    # Initialize the dataset and dataloaders
    train_dataset = ForgeryDataset(root_dir, split="train", transform_image=transform_image, transform_mask=transform_mask)
    test_dataset = ForgeryDataset(root_dir, split="test", transform_image=transform_image, transform_mask=transform_mask)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    # Instantiate the model, loss function, and optimizer
    model = UNet().to(device)
    criterion = nn.BCELoss()  # Binary Cross-Entropy Loss
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # Train the model
    train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, device)

    # Save the trained model
    torch.save(model.state_dict(), "forgery_detection_model2.pth")
    print("[INFO] Model saved")
